---
title: 'What models do you use?'
section: 'advanced'
tags: ['introduction', 'faq']
order: 1
---

# What models do you use?

We use multiple models to get better results: Claude Sonnet for most of the coding, Gemini Flash for quick tasks and to find relevant files, and we also use a speculative decoding model from Relace AI for fast file rewrites. We use o3-mini as a file editing fallback, and gpt-4o-mini for some trivial tasks.

We also have two modes, which slightly change the above set-up, mainly to achieve higher performance (in `max`) or lower cost (in `lite`):

- `--max`: uses Claude Sonnet and also pulls more files on your codebase to better handle complex problems.
- `--lite`: uses Claude Haiku for editing instead of Sonnet (~1/3 the cost). It also pulls fewer files, meaning that the context cost will be much smaller.
